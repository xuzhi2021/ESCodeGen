response_id,"Q: In your opinion, what should be considered when defining ""ethically sourced code generation""?",label,"Q: Have you ever encountered ethical sourcing issues while using, working with, or developing code generation models? Please describe. (If you have not, you may simply write ""No."")",label,"Q: After reading our dimensions, do you think you have encountered any situation where an ethically sourced code generation model was neededâ€”for example, when the code generated by models is from unknown sources, you were unsure if it was safe or legal to use? If yes, please briefly describe the situation.",label,Q: What do you think could be potential impacts or consequences of code generation models that are not ethically sourced (from the perspective of both model developers and users)?,label,"Q: Can you share any examples or experiences that illustrate why you think certain dimensions are relevant to the definition of ethically sourced code generation?
 If yes, please share your examples, experiences, or just your personal reasoning.",label,"Q: Based on the dimensions you have just considered, do you believe that any currently available code generation tools align with the definition of ethically sourced code generation? If yes, please list the name(s) of the tool(s) and briefly explain why.",label,"Q: Is there anything about ethically sourced code generation that you still find unclear, confusing, or difficult to define? Are there any other dimensions you think should be included? (If nothing comes to mind, you may simply write â€œNo.â€)",label
R_71Z1TZQQID1hnrl,The souce for generating the code should be recorded and traced,source acknowledgement;,"for example, I don't know whether the generated code is a copy of code from other sources","unknown sources;
generation distictiveness","Yes, because I am not sure if the code generated can be used in my product or not",IP,It makes the generated code unreliable and untrustable,unreliable and untrustable,It is based on my personal reasoning,personal reasoning,"no, my guess is that current tools do not align with the definition of ethically sourced code generation",n,"no, the points listed in this survey are quite comprehensive","n
comprehensive"
R_8Y34YAOnBbCcLQw,"Sustainability (Environmental impact)
 Contribution to authors if AI copies code snippets
 Some guarantee of code quality (e.g., security)
 No learning from input to avoid privacy issues","environment (sustainability, pollution?)
compensation
code quality;
code security
privacy","News on environmental impact and privacy issues through the model learning, low code quality","environment
privacy
code quality","New about the Environmental impact, and privacy violations of models","environment
privacy","Environmental issues, data leaks, using data that's copyrighted by developers","environment;
data leak (privacy)
licensing",News and research articles,news and research articles,no,n,no,n
R_2n2OxsREA7LAHIl,whether the code generated by teh AI contains material that could be violating copyright laws and whether it is understandable to verify whether it is safe,Licensing,No,,No,n,"possible legal issues, negative consequences on society if working conditions are bad or energy consumption too high","legal issues
bad working condition
energy consumption",I think the legal issues and the environmental issues are very important because they both are still uncertain and will have an huge effect on society in the coming years,"legal issue
environment impact
social impact","No, while I think that there will be improvements in the coming years, I think that the current technology is not developed enough to be classified ethically sourced","n, but improving",No,n
R_72TdKwJh2PEL0Zz,"- licensing and compliance
 - fairness both in terms of generating code that consider fairness and in terms of attributing code to the sources used during training 
 - privacy and security 
 - energy-awareness and efficiency","licensing;
fairness;
source acknowledgement
privacy
security
environment (energy consumption","Yes, all above","licensing;
fairness;
source acknowledgement
privacy
security
energy consumption",Most of the time these dimentions are not respected,Most of the dimension,"Monopolies, security threats, risks, copyright infringement etc.","Monopolies;
security
legal (licensing, infringement)",",",,No,n,No,n
R_3w7g55cN3ZXab0Z,"First and foremost, we need to consider environmental protection. Training GPT-3, which is an outdated model for now, can be responsible for producing CO2 equivalent to that of 5 cars over a lifetime, which is a significant amount. Even in the inference phase, it creates a massive amount of CO2. Therefore, if LLMs will stay and help developers, we need more specialized, smaller code generation models.
 
 Secondly, to maintain transparency and traceability, we need to apply the concept of supply chain, like tracking the origin of code (i.e., which public code closely aligns with the generated code)","environment (emissions and pollution);
transparency;
source acknowledgement; (trace source that aligns with the generated code);
supply chain;
stages (training, inference)","Current models face significant challenges with traceability. They generate code and ideas while citing sources that, in many cases, do not exist. Even when the cited sources are real, the information, ideas, or code provided by these models are not actually found in those sources.","traceability, source acknowledgement;;
cheating on source explanation -> integrity - honesty
;

","I often think about whether a piece of code is safe or legal when it uses a third-party library or API. Sometimes I have my API keys, and I want to avoid posting them on any unknown website.",privacy,The model could reveal very sensitive information about an entity.,privacy leak,No,,I don't believe such a model exists. Companies now prioritize productivity over reliable and ethically sourced code. I fear we may see catastrophic effects in a few years.,"n
Companies now prioritize productivity over reliable and ethically sourced code",No,n
R_4Euo5ZsbRnQqAsb,Code that is free from bias and properly sourced without copyright violations,"fairness;
licensing",No,,Using code from certain github repositories or packages developed by others for Proprietary softwares,IP,Ould potentially deter deep thinking and understanding before code deployment,User-cognitive (reliance on code generation),Fairness especially in the way models are trained and the bias of the inherent training data could largely affect model outputs and have a large impact on a society that is increasingly building upon AI generated outputs.,"fairness: 
social impact of model output",No,n,No,n
R_9LunYQ15josaj9L,The creation process of the code generation model and tool should always follow an ethical standard.,process / stages,Very few cases such as generating impolite responses or code with license issues.,"licensing;
impolite response (equity - fairness)",I want to be assured when using code generation models. I don't want to get troubled when the code I am using generated by the model has ethical issues.,IP,Social stress of using unethical code generated by models.,low social acceptability,"Some models are developed by people who work overtime and the competition is not fair, by sacrificing our personal time.","exploitation (overtime
increase competition","No, nearly all of them","n, nearly all",No,n
R_4FJq1kejEMyQ5m1,"privacy, security, and consent","privacy;
security;
consent",No,,"Yes, when the model reads my requirements, and it generates some unverified code.",code quality,may generate unsafe codes and affect the reliability of the software,"security
reliability",N/A,,n/a,n,No,n
R_3P4WVat2FdaAAJC,"software license, malware, vulnerable code, privacy related","licensing;
malware contamination;
code quality (vulnerability)
privacy","yes, credential leakage",privacy / security,No,n,malware,security / contamination,No,,No,n,No,n
R_7lhLoDNDS6prko7,"Whose code is being used, and whether they have provided permission to use it. Some code may be in public repos for anyone to use, but in other cases, people will want credit for their work. Also, it matters whether the code generated is accurate.","source acknowledgement;
consent / licensing
compensation
code quality (accuracy);",Not for code specifically.,,Not for code specifically.,n,"Some potential impacts are the model developers taking credit for a programmer’s work, or the programmer’s work being misrepresented. For the user, the model may display inaccurate code just because that was the most widely available version in the training dataset.","wrong contribution attribution
inaccuracy","Representation and fairness are important to ethically sourced code generation. LLMs may generate code that isn’t inclusive and unbiased, especially if the training data contains such code. For simple code, it may be a variable like “bool gender” (instead of enum or string), which would suggest gender is binary. For code involving machine learning, the model may be trained on a dataset that only encompasses a small sample of the population. If the sample is biased, and the LLM does not say so, there is a risk of that data being extrapolated too far.","equity - fairness (inclusive
data being extrapolated)
representation","No, I believe existing code generation models and their developers are primarily focused on profit and not ethics.","n
profit rather than ethics",No.,n
R_6fhyuaQTCPuyNm9,The LLM should be able to point out what are the exact pieces of code that were used as sources for the generation of the code that is provided as an answer to a prompt/question. This is just one example. I suspect that there are many other considerations.,source acknowledgement;,No,,"Yes, I am always thinking about that issue.",y,"The training could be done by including leaked code that is originally subject to copyrights, This effectively violates the copyright, which affects the author of the code. Potentially, the users could be liable if they use the generated code.","leak (privacy)
licensing (infringement
), 
legal issue for user",I dont have an example,,"No, I am not aware of any, though I have not use LLMs extensively for code generation.",n,no,n
R_51vWJoGYtchQm2Y,"License, ownership, accontability","licensing;
IP;
accountability",No,,N/A,n,"Legal issues in case of accidents (who is accountable?), human developers not getting the recognition or compensation they deserve","legal issue (ambiguous accountability)
lack compensation for source developer",N/A,,"Maybe only the open ones (e.g., Llama), but still partially",partially,No,n
R_6Zp6FQgp3iIcxMd,"Source of training and fine-tuning data, compensation for data annotation workers","source
fair wage (annotator)",No,,No,n,Unsafe and/or unlicensed code,"security
licensing",No,,No. One cannot acertain that only public domain and/or open-sourced code is used in the training/fine-tuning of models.,"n
uncertain whether they only use public domain code to train model",No,n
R_5gOCMoLcOBCOlky,"The source of data used to train the code generation models; the model training processes; the code generation processes (i.e., model inference).","source
stages (training and post-deployment (inference))",No,,"In all uses of code generation models, I think ethically sourced code generation models are needed.",y,"Security issues: hackers may leave backdoors in the training data to achieve adversarial goals. IP issues: IPs of code may not be respected. Privacy issues: some privacy information in certain code (e.g., sensitive configuration information) may be exposed.","security
IP
privacy leak","For example, low quality or contamination in the training data could lead to the generation of seemingly correct but in fact faulty code, wasting developers' time in debugging. Some developers of the training code could risk exposing their sensitive information (e.g., account info) unintentionally embedded in the code.","low-quality training data
inaccurate output 
contamination
privacy leak",I am not aware of any such tool.,n,No,n
R_5s0Fi1mVHsT4T9l,"This includes training data quality and curation standards to avoid buggy, insecure, or low-quality code in datasets while respecting intellectual property and licensing requirements. The generation process itself must incorporate clear prompt engineering to prevent ambiguous outputs, well-designed agentic workflows for retrieval and testing, security-by-design integration, and bias detection mechanisms. Output quality factors encompass code maintainability, security vulnerability prevention, technical debt minimization, and appropriate human oversight checkpoints. These factors collectively ensure that each step from data sourcing through final code delivery meets ethical and sustainable standards.","code quality (vulnerability);
code security
IP, licensing;
model design (for output quality);
fairness (bias);
environment (sustainability","Yes, I sometimes encounter unsustainable code or package releases by prestigious academic organizations.",unsustainable code (code quality),"Well, this quite depends, when the codegen model is powerful enough, for example, OpenAI-level model, although not transparent enough, I would still use it for real-world inference purposes.","neural
code quality","The software license might not be respected, and the code would be reused in an appropriate manner. Even worse, there are chances to generate buggy codes (that's why we need a platform such as SWE Arena: https://huggingface.co/spaces/SE-Arena/Software-Engineering-Arena :)","licensing
inaccuracy","This represents a fascinating and relatively unexplored direction that I hadn't fully considered before. A critical dimension is governance and decision-making authority ”who determines the ethical tradeoffs when competing values conflict? While everyone might agree that generated code should be transparent, private, trustworthy, sustainable, responsible, and uncontaminated, these dimensions often conflict in practice.
 
 For example, you cannot achieve 100% transparency and privacy simultaneously” making code completely open conflicts with protecting sensitive data or proprietary algorithms. Similarly, creating highly sustainable code may come at significant costs in development time, computational resources, or feature completeness. The challenge becomes even more complex when considering future-proofing: how do you make code sustainable for unknown future requirements without over-engineering or creating unnecessary complexity?","values conflict (trade-off within dimensions)
transparency and privacy can conflict
uncontaminated
computing resource, environment","Perhaps no. However, some tools demonstrate stronger practices in certain areas. For example, Anthropic Claude Code demonstrates consideration for security-by-design and refuses to generate malicious code, but lacks comprehensive sustainability metrics or transparent training data standards.","maybe n (partially),
improving, like Anthropic Claude Code for security (refuse to generate malicious code), lack transparency, sustainability","Code quality attributes, such as sustainability, might be seen as a technical standard rather than a moral imperative. This is just my personal view for reference.",sustainability -> code quality -> technical rather than ethical
R_5JJjm4Ih2vVLMLT,"The security of the generated code, whether the generated code contains a pre-trained corpus, and whether the generated code contains harmful content.","code security
generation distictiveness;
fairness (harmful content)",No,,No. As long as it functions well and passes the test I don't concern the sources,"no
code quality","Generate buggy code, or violate intellectual properties of other code base","buggy code (inaccuracy)
IP","LLM generates buggy code, or directly reuses code from other proprietary codebase","code quality
IP
generation distictiveness",I have no idea because there are few evaluation on existing work,"not know
lack of evaluation on existing work",No,n
R_79JYDM8bjbmhKcV,"1. Energy used for inference should not contribute to climate change
 2. Data used for training should be collected in accordance with its license and privacy rules
 3. Prompting data should not be stored, or should be stored securely, and deleted on demand
 4. There should be no discrimination in providing access to AI","environment (sustainability, pollution and emissions, energy consumption);
stage (inference)
licensing;
privacy (not storing prompt/input);
accessibility","Major AI companies like OpenAI and Anthropic have chosen to block access to their models in certain countries where I live and work. This policy creates unfair barriers and can be seen as a discriminatory practice, as it restricts equal access to cutting-edge technologies based solely on location.",accessibility,No,n,"Potential negative impacts:
 - Violations or licenses
 - Discrimination
 - Raise of inequality by limiting access to models","licensing
discrimination (by limited access)","Limiting access to AI in certain counties will raise inequality, discrimination and promote unfair competition practices.","
inequilty, discrimination (by limited access)
unfair competition","Model families like LLAMA and QWEN are more ethically sourced, however more transparency is desirable.","partially
 LLAMA and QWEN
more transparency is desirable","I do not know what ""post deployment"" is.","stage ""post deployment"" is not that clear"
R_8fZUKmchakpWAzD,"The training data used to create the model (contents, origin, acquisition of data, licensing/copyright of data), carbon footprint of training/tuning/use, hardware for training and use, origin of the code used to train the model, guardrails to prevent misuse of models","licensing;
environment (emissions;
computnig resource (energy consumption);
source acknowledgement;
preventing misuse",Some work on carbon footprint/energy consumption,environment (energy consumption),There is always a concern when working with industrial partners about whether the generated code is free from copyrighted/licensed material. They only want to use code that they can claim ownership of in the end.,"license, IP",Carbon footprint is a huge issue that is not really being addressed sufficiently. Fairness and ownership are important too.,"environment (emissions)
fairness
IP",Nothing coming to mind,,No,n,Nothing comes to mind,n
R_9Mll9Sn5t5uZtW3,"license compliance, pii mindfulness","licensing;
privacy",No,,No,n,"Copyright violations, which are bad. To a lesser extent, environmental risks.","IP
environment",Licensing is a fairly straightforward issue. I'm less sure about other issues.,licensing,"StarCoder, if I understood correctly, took a lot of care in data curation, making training data transparent, so it is a positive example.","y
StarCoder (data curation, transparency)",No,n
R_1YMs6OYDKUKu62d,"mostly where the model is created from an ethical process, e.g., minimizing bias, protecting privacy, and preventing misuse.","fairness;
privacy;
preventing misuse",no,,"Yes, I don't think existing popular chat-based LLM-driven coding assistant tools/APIs make ethical parts very clear, so it is unclear if it was safe or legal to use. I assume big companies would have a legal team working on this, so it may be handled well already.","legal;
transparency","Biased evaluation of the models, misuse of models.","biased evaluation
misuse",I think they are captured well.,all good,"I don't think closed models could make everything open to everyone. But opensource models, e.g., Starcoder, which are created upon open source data, could be easier to judge.","partially
StarCoder (open-sourced model, data)",No,n
R_21sTPCYiiqxLrCH,"Origin of training data should be in public domain and adhere to existing licenses, models training costs and impact on environment, models inference costs and impact on environment","licensing (IP)
environment (sustainability, pollution);
stages(training, post-deployment (inference))",Not personally,,There were rumors the initial versions of GitHub Copilot used training data from private repositories.,"privacy;
consent","Sensitive data leakage, possible legal repercussions on illegally sourced training data that is not transformative enough, environmental impact of training larger model for longer","privacy leak
illegal sourced training data (IP, generation distinctiveness, consent?)
environmental impact",They all are relevant in their self-evident way,all good,"No. As far as I am aware, even finetuned models on opensource coding datasets are based on existing models trained on data of unknown origin.","n
unknown data source","User-Cognitive (effects of reliance on code generation models, dependency)","User-Cognitive (effects of reliance on code generation models, dependency)"
R_4g8GeY7fcdt6sLf,The datasets being used for training the data and the licenses of the repositories being used,"source;
licensing","Yes, discussing how much code can be generated by a model and the issues of ownership",IP,"Yes, this would be in case of companies who have competitors where the solution space is similar. In case of legal disputes (e.g. Oracle vs Google), the risk of having code without traceability that is generated by a code generation model may lead to intellectual property difficulties","source acknowledgement
IP",Developers will have to track development in order to not have IP scandals,"IP
","To me traceability and sustainability are important as the former allows to give some trust into the generation while the latter makes developers focused on creating efficient systems for model development, alongside it being ethically sourced","source acknowledgement
code quality",I do not think there is such a tool currently,n,No,n
R_5rOAjbxhB7W7Ieu,"The training data source, the functionality of output code.","source;
accuracy / functionality",No,,When the code from adversarial sources.,integrity - contamination,Users get vulnerable code.,inaccuracy (vulneribility),No,,"Based on my experience, I haven't encountered unethical outputs from the models so far. However, the data collection process is concerning. I believe these models have already scraped a large amount of data from the internet without the authors' consent. While this practice conflicts with the idea of ethically sourced code generation, it's currently difficult to avoid.","partially
no unethical output
data collection lack of consent",No,n
R_8343dcoK8VYLqZb,"Ethically sourced products have paid fair wages, did not pollute etc.","fair wage;
emissions and pollution",The question is really wrong here. You don't know rhe meaning of ethically sourcing things. Nobody enounters problem of ethically sourcing chocolate when *buying* a bar of chocolate (which is your question as you ask about generation of code). They meet it at *producing* it and in your example would be training and not working with,,Use of common sources for training. See the next question for an answer.,"IP
contamination",The tragedy of the commons. Less and less people will.contribute to the commons and then the overall quality will decline as the code generated by the models will start entering into the common pool and the model will start eating its own food as if it was independly generated without realizing,"IP
contamination
impact on open-source environment",Exploting people communal respurces to make money is an example of practices that fair trade tries to address,"exploitation
fair trade",None,n,Confusing production with generation,Confusing production with generation
R_1wv1XV5XLvooQmt,"Security, decoupling","security
code quality (decoupling)",No,,"Yes, when generating some shell script code, it will feel insecure and I will perform a code review","code security 
code quality","1. unemployment, 2. software security concerns, 3. irrational code generation increasing software maintenance code costs","unemployment
code security
accuracy (code quality)",No,,No,n,No,n
R_5NsmXpKRrkR8Pkt,"Whether the training data was improperly sourced from private or enterprise repositories; and whether the training was conducted using legitimate computing resources, rather than using compromised (botnet) machines.","consent (legal way to obtain training data)
legal computing resource",No,,No,n,Privacy Leaks. Private repositories or corpus with property rights protection are used for training and can be easily generated by the model.,"privacy leak
IP (licensing)
generation distictiveness",No,,"No. Basically, they are not open and transparent, and a large number of models are suspected of leaking private data.","n
lack of transparency
privacy leak",No,n
R_6ONrKFGeY8wotYR,Opt in consent.,consent (opt-in),"Yes, I was debating whether I should train on a specific dataset I had gathered when I realized I could ask the source of the data if they were okay with the training before I did it.",consent,"In school, many people would use ChatGPT without any sourcing and get called out when it hallucinated false information.",code quality,"Exploitation of developers work, monopolization of generative AI, and less diversity in outputs.","exploitation of sourced code developers (IP, consen)
monopolization
reduce diversity in output
",My friend is a very good artist and has been affected very negatively by AI Generated art. Her and I have discussed for a very long time about how it's not okay to use people's work without their consent being freely and willingly given because otherwise the use of their work is theft.,"consent
IP
negative impact on artists (a friend)",OLMo2 uses ethically sourced data and doesn't use data without consent while still getting very good performance. They also list all the licenses of which they are using the data under.,"y
OLMo2
consent
good performance
licensing",No.,n
R_2rCSuYQxs0wNUy2,Recurring financial compensation to authors of input training data based on license fees,"compensation;
licensing","All AI models based on web scraping are inherently unethical, so yes.",consent,No,n,"Exploitation of labor, more projects being closed source to avoid scraping etc","exploitation (labor rights)
impact open-source environment",No,,No,n,No,n
R_8XaiuHzyZCyvrQE,"Source code used to train the model should only be obtained with explicit permission from developers, where the license is fully permissive or in the public domain, i.e., not GPL, and where the dataset is made public so the public can critique the training data.","consent (opt-in);
licensing
transparency (training data);","Yes. In some cases, I have not had confidence that the generated code did not require attributing code that was licensed under a non-permissive FOSS license.",licensing,"All LLMs and code generation tools are in legal limbo as it is unclear whether the collection of data, the training of the model, and the generating of output falls under fair-use. Also, in different countries. Additionally, the push to integrate these models into areas where they aren't necessary means that their environmental and social impact is easier to amplify. For example, I don't know the impact of using GitHub Copilot to review a PR. Is it more environmentally friendly for me to review the PR myself?","legal;
transparency
stage (data collection, training, output)
environment","Software will become more closed as developers will realise that their code will land up in a LLM if they make it public. Furthermore, users of software may be reluctant to use it if they aren't sure if it is ethically created. For example, what about IP violations, copyright violations, and social impacts of the software?","impact open-source environment
user prefer not to use
IP
social impact","I don't feel comfortable sharing my own code online as I don't want it used by a large company in their LLM when it will (1) generate more pollution, (2) take away jobs from software developers, and (3) potentially violate the license under which I published by code.","contamination
unemployment
licensing","I am glad that some people are creating software datasets where users can opt to remove their repos, though it should have been opt-in and not opt-out. Some companies have looked at small models, but they haven't become popular. This means that most code generation requires power-hungry hardware.","partially
opt-out is good, but should be opt-in
computing resource",No,n
R_7hmfnlkvPiXWf3v,"1. If the code is not self-authored, its source should be clearly disclosed.
 2. The quality of the generated code should be ensured.
 3. Developers should be familiar with and understand the code that is generated.","transparency;
code quality",No,,No,n,"Unethically sourced code generation could lead to legal risks, security vulnerabilities, and low-quality code.
 For developers, it may damage reputation and violate licensing terms.
 For users, it could result in unreliable software and hidden dependencies.","ligal risk
security
code quality (vulneratibility)
damage reputation
IP
low quality output (unreliable code and hidden dependencies)","Some tools generate code copied from public repositories without clear attribution, which raises concerns about licensing and ownership. This shows the importance of transparency and traceability in ethically sourced code generation.","transparency (unclear source)
IP
licensing
acknowledgement","Most tools still lack full transparency and licensing clarity. However, tools that provide citation, allow opt-outs for training data, or offer explainability features are moving in the right direction. I don't think any tool fully meets the ethical standard yet, but some are making progress.",partially,No,n
R_8ydrGlZcCbzwI4D,"Models should only be trained on code voluntarily offered up by developers, on an opt-in basis, and never scraped without consent, including even MIT licensed open source code, which was released as such before the proliferation of LLMS.","consent (opt-in);
licensing",No.,,"No specific example, but this is a general concern.",n,"Intellectual property theft. The further fueling of dishonst narratives in an attempt to undermine skilled labour. Downward pressure on quality and standards at the expense of users. The introduction of additional security exploits. Further monopilisation, and exacerbated inequality.","IP
fuel of dishonest
exploitation
low quality
security
monopilisation
inequity","AI companies continuously scraping data, stealing intellectual property, ignoring explicit instructions not to (e.g. robots.txt), and running up hosting expenses for the privilage! Externalising the cost of their theft.","consent
IP
crawling cost hosting expenses, finalcial loss of hosting",No.,n,"Details around serious regulation, which is sorely needed.",serious regulation
R_8jXQJBTj3xGS41P,"Where does the training data come from, and what kind of energetic input is needed for training the data and further generation of code.","source acknowledgement;
environment (energy consumption","Yes, lack of transparency from big models on where the data is sourced from. Does it use source code protected by licenses meant to keep the code open to the community, such as GPL/AGPL?","transparency;
licensing","Yes, most of the ChatGPT usage is unclear where the model gets its trained code, and therefore it is unclear if it's licensed in any particular way.","transparency;
licensing",Users could be ultimately legally responsible for violating code licenses that they are not aware of.,user: IP,"When using a 3rd party library, it is often important to make sure that the license on that library is compatible with the library in the project, specially when the project is a for-profit closed-source one. In the same way, it is important to know where the code comes from in code generated by models.","license compatibility between code repo and dependencies/libraries
transparency / source acknowledgement",No,n,No.,n